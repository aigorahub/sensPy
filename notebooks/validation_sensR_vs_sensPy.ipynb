{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sensR vs sensPy Validation Notebook\n",
    "\n",
    "This notebook calls both **sensR** (R) and **sensPy** (Python) side-by-side to validate numerical parity.\n",
    "\n",
    "### Requirements\n",
    "- R with `sensR` package installed (`install.packages(\"sensR\")`)\n",
    "- Python: `rpy2`, `senspy`, `numpy`, `pandas`\n",
    "\n",
    "```bash\n",
    "pip install rpy2 pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "\n",
    "# rpy2 for calling R\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import r, FloatVector, IntVector, StrVector\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# sensPy\n",
    "import senspy\n",
    "from senspy import (\n",
    "    discrim, betabin, twoac, samediff, anota, dod, dod_fit,\n",
    "    discrim_power, dprime_power, discrim_sample_size, dprime_sample_size,\n",
    "    dprime_test, dprime_compare, dprime_table,\n",
    "    rescale, psy_fun, psy_inv, psy_deriv,\n",
    "    sdt, roc, auc,\n",
    "    pc_to_pd, pd_to_pc,\n",
    ")\n",
    "\n",
    "# Load sensR\n",
    "sensR = importr('sensR')\n",
    "base = importr('base')\n",
    "stats = importr('stats')\n",
    "\n",
    "# Helper to compare results\n",
    "def compare(label, py_val, r_val, tol=1e-4):\n",
    "    py_val = float(py_val)\n",
    "    r_val = float(r_val)\n",
    "    match = abs(py_val - r_val) < tol\n",
    "    status = 'PASS' if match else 'FAIL'\n",
    "    print(f\"  {status} | {label:30s} | sensPy={py_val:12.6f} | sensR={r_val:12.6f} | diff={abs(py_val-r_val):.2e}\")\n",
    "    return match\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. `discrim()` — Discrimination Analysis\n",
    "\n",
    "Test across multiple protocols and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"1. discrim() — Basic discrimination analysis\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "test_cases = [\n",
    "    {\"correct\": 80, \"total\": 100, \"method\": \"triangle\", \"statistic\": \"exact\"},\n",
    "    {\"correct\": 60, \"total\": 100, \"method\": \"duotrio\", \"statistic\": \"exact\"},\n",
    "    {\"correct\": 75, \"total\": 100, \"method\": \"twoafc\", \"statistic\": \"likelihood\"},\n",
    "    {\"correct\": 50, \"total\": 100, \"method\": \"threeafc\", \"statistic\": \"wald\"},\n",
    "    {\"correct\": 45, \"total\": 100, \"method\": \"tetrad\", \"statistic\": \"score\"},\n",
    "    {\"correct\": 30, \"total\": 100, \"method\": \"twoafc\", \"statistic\": \"exact\"},\n",
    "    {\"correct\": 90, \"total\": 120, \"method\": \"triangle\", \"statistic\": \"likelihood\"},\n",
    "]\n",
    "\n",
    "for tc in test_cases:\n",
    "    print(f\"\\n--- correct={tc['correct']}, total={tc['total']}, method={tc['method']}, stat={tc['statistic']} ---\")\n",
    "    \n",
    "    # Python\n",
    "    py = discrim(tc[\"correct\"], tc[\"total\"], method=tc[\"method\"], statistic=tc[\"statistic\"])\n",
    "    \n",
    "    # R\n",
    "    r_res = sensR.discrim(tc[\"correct\"], tc[\"total\"], method=tc[\"method\"], statistic=tc[\"statistic\"])\n",
    "    r_coef = stats.coef(r_res)\n",
    "    \n",
    "    compare(\"d_prime\", py.d_prime, r_coef.rx2(\"d.prime\")[0])\n",
    "    compare(\"pc\", py.pc, r_coef.rx2(\"pc\")[0])\n",
    "    compare(\"pd\", py.pd, r_coef.rx2(\"pd\")[0])\n",
    "    compare(\"se_d_prime\", py.se_d_prime, r_res.rx2(\"coefficients\")[1])\n",
    "    compare(\"p_value\", py.p_value, r_res.rx2(\"p.value\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. `discrim()` — Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"2. discrim() — Confidence Intervals\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "ci_cases = [\n",
    "    {\"correct\": 80, \"total\": 100, \"method\": \"triangle\", \"statistic\": \"exact\"},\n",
    "    {\"correct\": 60, \"total\": 100, \"method\": \"twoafc\", \"statistic\": \"likelihood\"},\n",
    "    {\"correct\": 70, \"total\": 100, \"method\": \"duotrio\", \"statistic\": \"wald\"},\n",
    "]\n",
    "\n",
    "for tc in ci_cases:\n",
    "    print(f\"\\n--- {tc['method']}, stat={tc['statistic']}, correct={tc['correct']}/{tc['total']} ---\")\n",
    "    \n",
    "    py = discrim(tc[\"correct\"], tc[\"total\"], method=tc[\"method\"], statistic=tc[\"statistic\"])\n",
    "    r_res = sensR.discrim(tc[\"correct\"], tc[\"total\"], method=tc[\"method\"], statistic=tc[\"statistic\"])\n",
    "    \n",
    "    for param in [\"d_prime\", \"pc\", \"pd\"]:\n",
    "        py_ci = py.confint(parameter=param)\n",
    "        r_param = {\"d_prime\": \"d.prime\", \"pc\": \"pc\", \"pd\": \"pd\"}[param]\n",
    "        r_ci = stats.confint(r_res, **{\"parm\": r_param})\n",
    "        compare(f\"CI lower ({param})\", py_ci[0], r_ci[0])\n",
    "        compare(f\"CI upper ({param})\", py_ci[1], r_ci[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. `discrim()` — Similarity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"3. discrim() — Similarity Tests (d_prime0 / pd0)\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "sim_cases = [\n",
    "    {\"correct\": 40, \"total\": 100, \"method\": \"triangle\", \"d_prime0\": 1.0, \"statistic\": \"exact\"},\n",
    "    {\"correct\": 55, \"total\": 100, \"method\": \"twoafc\", \"d_prime0\": 0.5, \"statistic\": \"likelihood\"},\n",
    "]\n",
    "\n",
    "for tc in sim_cases:\n",
    "    print(f\"\\n--- {tc['method']}, d_prime0={tc['d_prime0']}, stat={tc['statistic']} ---\")\n",
    "    \n",
    "    py = discrim(tc[\"correct\"], tc[\"total\"], method=tc[\"method\"],\n",
    "                 d_prime0=tc[\"d_prime0\"], statistic=tc[\"statistic\"], test=\"similarity\")\n",
    "    r_res = sensR.discrim(tc[\"correct\"], tc[\"total\"], method=tc[\"method\"],\n",
    "                          **{\"d.prime0\": tc[\"d_prime0\"]}, statistic=tc[\"statistic\"], test=\"similarity\")\n",
    "    \n",
    "    r_coef = stats.coef(r_res)\n",
    "    compare(\"d_prime\", py.d_prime, r_coef.rx2(\"d.prime\")[0])\n",
    "    compare(\"p_value\", py.p_value, r_res.rx2(\"p.value\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. `rescale()` — Scale Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"4. rescale() — Convert between pc, pd, d_prime\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "protocols = [\"triangle\", \"twoafc\", \"duotrio\", \"threeafc\", \"tetrad\"]\n",
    "\n",
    "# From d_prime\n",
    "for method in protocols:\n",
    "    for dp in [0.5, 1.0, 2.0, 3.0]:\n",
    "        py_res = rescale(d_prime=dp, method=method)\n",
    "        r_res = sensR.rescale(FloatVector([dp]), method=method)\n",
    "        r_coef = stats.coef(r_res)\n",
    "        \n",
    "        ok1 = compare(f\"{method} d'={dp} -> pc\", py_res.pc, r_coef.rx2(\"pc\")[0])\n",
    "        ok2 = compare(f\"{method} d'={dp} -> pd\", py_res.pd, r_coef.rx2(\"pd\")[0])\n",
    "\n",
    "print(\"\\n--- From pc ---\")\n",
    "for method in [\"triangle\", \"twoafc\"]:\n",
    "    for pc_val in [0.5, 0.7, 0.9]:\n",
    "        py_res = rescale(pc=pc_val, method=method)\n",
    "        r_res = sensR.rescale(pc=FloatVector([pc_val]), method=method)\n",
    "        r_coef = stats.coef(r_res)\n",
    "        compare(f\"{method} pc={pc_val} -> d'\", py_res.d_prime, r_coef.rx2(\"d.prime\")[0])\n",
    "\n",
    "print(\"\\n--- From pd ---\")\n",
    "for method in [\"triangle\", \"twoafc\"]:\n",
    "    for pd_val in [0.2, 0.5, 0.8]:\n",
    "        py_res = rescale(pd=pd_val, method=method)\n",
    "        r_res = sensR.rescale(pd=FloatVector([pd_val]), method=method)\n",
    "        r_coef = stats.coef(r_res)\n",
    "        compare(f\"{method} pd={pd_val} -> d'\", py_res.d_prime, r_coef.rx2(\"d.prime\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. `psy_fun()` / `psy_inv()` / `psy_deriv()` — Psychometric Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"5. psyfun / psyinv / psyderiv — Psychometric link functions\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "d_primes = [0.0, 0.5, 1.0, 1.5, 2.0, 3.0]\n",
    "protocols = [\"triangle\", \"twoafc\", \"duotrio\", \"threeafc\", \"tetrad\"]\n",
    "\n",
    "for method in protocols:\n",
    "    print(f\"\\n--- {method} ---\")\n",
    "    for dp in d_primes:\n",
    "        # psyfun: d' -> pc\n",
    "        py_pc = float(psy_fun(dp, method=method))\n",
    "        r_pc = float(sensR.psyfun(dp, method=method)[0])\n",
    "        compare(f\"psyfun d'={dp}\", py_pc, r_pc)\n",
    "    \n",
    "    # psyinv: pc -> d'\n",
    "    pc_vals = [0.5, 0.7, 0.9]\n",
    "    for pc_val in pc_vals:\n",
    "        py_dp = float(psy_inv(pc_val, method=method))\n",
    "        r_dp = float(sensR.psyinv(pc_val, method=method)[0])\n",
    "        compare(f\"psyinv pc={pc_val}\", py_dp, r_dp)\n",
    "    \n",
    "    # psyderiv\n",
    "    for dp in [0.5, 1.0, 2.0]:\n",
    "        py_deriv = float(psy_deriv(dp, method=method))\n",
    "        r_deriv = float(sensR.psyderiv(dp, method=method)[0])\n",
    "        compare(f\"psyderiv d'={dp}\", py_deriv, r_deriv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. `betabin()` — Beta-Binomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"6. betabin() — Beta-Binomial overdispersion model\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "# Panel data: (correct, total) per panelist\n",
    "data = np.array([\n",
    "    [3, 10], [5, 10], [7, 10], [4, 10], [6, 10],\n",
    "    [8, 10], [2, 10], [5, 10], [9, 10], [4, 10],\n",
    "])\n",
    "\n",
    "for corrected in [True, False]:\n",
    "    for method in [\"duotrio\", \"triangle\", \"twoafc\"]:\n",
    "        print(f\"\\n--- method={method}, corrected={corrected} ---\")\n",
    "        \n",
    "        # Python\n",
    "        py = betabin(data, method=method, corrected=corrected)\n",
    "        \n",
    "        # R\n",
    "        r_data = ro.r.matrix(IntVector(data.flatten()), nrow=data.shape[0], ncol=2, byrow=True)\n",
    "        r_res = sensR.betabin(r_data, method=method, corrected=corrected)\n",
    "        r_coef = stats.coef(r_res)\n",
    "        \n",
    "        compare(\"mu\", py.mu, r_coef[0])\n",
    "        compare(\"gamma\", py.gamma, r_coef[1])\n",
    "        compare(\"log_likelihood\", py.log_likelihood, float(r_res.rx2(\"logLik\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. `twoac()` — 2-AC Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"7. twoac() — 2-Alternative Constant protocol\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "twoac_cases = [\n",
    "    {\"data\": [40, 20, 60], \"statistic\": \"likelihood\"},\n",
    "    {\"data\": [30, 40, 50], \"statistic\": \"wald\"},\n",
    "    {\"data\": [10, 80, 30], \"statistic\": \"likelihood\"},\n",
    "    {\"data\": [55, 10, 35], \"statistic\": \"likelihood\"},\n",
    "]\n",
    "\n",
    "for tc in twoac_cases:\n",
    "    print(f\"\\n--- data={tc['data']}, stat={tc['statistic']} ---\")\n",
    "    \n",
    "    # Python\n",
    "    py = twoac(tc[\"data\"], statistic=tc[\"statistic\"])\n",
    "    \n",
    "    # R\n",
    "    r_res = sensR.twoAC(IntVector(tc[\"data\"]), statistic=tc[\"statistic\"])\n",
    "    r_coef = r_res.rx2(\"coefficients\")\n",
    "    \n",
    "    compare(\"tau\", py.tau, r_coef[0])      # [0,0]\n",
    "    compare(\"d_prime\", py.d_prime, r_coef[1])  # [1,0]\n",
    "    compare(\"se_tau\", py.se_tau, r_coef[2])    # [0,1]\n",
    "    compare(\"se_d_prime\", py.se_d_prime, r_coef[3])  # [1,1]\n",
    "    compare(\"log_likelihood\", py.log_likelihood, float(r_res.rx2(\"logLik\")[0]))\n",
    "    if py.p_value is not None:\n",
    "        compare(\"p_value\", py.p_value, float(r_res.rx2(\"p.value\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. `samediff()` — Same-Different Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"8. samediff() — Same-Different protocol\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "sd_cases = [\n",
    "    {\"ss\": 45, \"ds\": 5, \"sd\": 20, \"dd\": 30},\n",
    "    {\"ss\": 80, \"ds\": 20, \"sd\": 10, \"dd\": 90},\n",
    "    {\"ss\": 30, \"ds\": 10, \"sd\": 15, \"dd\": 25},\n",
    "]\n",
    "\n",
    "for tc in sd_cases:\n",
    "    print(f\"\\n--- ss={tc['ss']}, ds={tc['ds']}, sd={tc['sd']}, dd={tc['dd']} ---\")\n",
    "    \n",
    "    # Python\n",
    "    py = samediff(nsamesame=tc[\"ss\"], ndiffsame=tc[\"ds\"],\n",
    "                  nsamediff=tc[\"sd\"], ndiffdiff=tc[\"dd\"])\n",
    "    \n",
    "    # R\n",
    "    r_res = sensR.samediff(nsamesame=tc[\"ss\"], ndiffsame=tc[\"ds\"],\n",
    "                           nsamediff=tc[\"sd\"], ndiffdiff=tc[\"dd\"])\n",
    "    r_coef = r_res.rx2(\"coefficients\")\n",
    "    \n",
    "    compare(\"tau\", py.tau, r_coef[0])\n",
    "    compare(\"delta (d')\", py.delta, r_coef[1])\n",
    "    compare(\"se_tau\", py.se_tau, r_coef[2])\n",
    "    compare(\"se_delta\", py.se_delta, r_coef[3])\n",
    "    compare(\"log_likelihood\", py.log_likelihood, float(r_res.rx2(\"logLik\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. `anota()` — A-Not-A Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"9. anota() — A-Not-A protocol\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "anota_cases = [\n",
    "    {\"x1\": 80, \"n1\": 100, \"x2\": 90, \"n2\": 100},\n",
    "    {\"x1\": 60, \"n1\": 80, \"x2\": 70, \"n2\": 80},\n",
    "    {\"x1\": 40, \"n1\": 50, \"x2\": 45, \"n2\": 50},\n",
    "]\n",
    "\n",
    "for tc in anota_cases:\n",
    "    print(f\"\\n--- x1={tc['x1']}, n1={tc['n1']}, x2={tc['x2']}, n2={tc['n2']} ---\")\n",
    "    \n",
    "    # Python\n",
    "    py = anota(tc[\"x1\"], tc[\"n1\"], tc[\"x2\"], tc[\"n2\"])\n",
    "    \n",
    "    # R\n",
    "    r_res = sensR.AnotA(tc[\"x1\"], tc[\"n1\"], tc[\"x2\"], tc[\"n2\"])\n",
    "    \n",
    "    compare(\"d_prime\", py.d_prime, float(r_res.rx2(\"dprime\")[0]))\n",
    "    compare(\"se_d_prime\", py.se_d_prime, float(r_res.rx2(\"se\")[0]))\n",
    "    compare(\"p_value\", py.p_value, float(r_res.rx2(\"p.value\")[0]))\n",
    "    compare(\"hit_rate\", py.hit_rate, float(r_res.rx2(\"hit.rate\")[0]))\n",
    "    compare(\"false_alarm_rate\", py.false_alarm_rate, float(r_res.rx2(\"fa.rate\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. `dod()` — Degree of Difference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"10. dod() — Degree of Difference model\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "# Example DOD data (4 response categories)\n",
    "dod_cases = [\n",
    "    {\"same\": [25, 22, 33, 20], \"diff\": [10, 15, 30, 45]},\n",
    "    {\"same\": [40, 30, 20, 10], \"diff\": [5, 15, 30, 50]},\n",
    "]\n",
    "\n",
    "for tc in dod_cases:\n",
    "    print(f\"\\n--- same={tc['same']}, diff={tc['diff']} ---\")\n",
    "    \n",
    "    # Python\n",
    "    py = dod(tc[\"same\"], tc[\"diff\"])\n",
    "    \n",
    "    # R\n",
    "    r_res = sensR.dod(IntVector(tc[\"same\"]), IntVector(tc[\"diff\"]))\n",
    "    \n",
    "    compare(\"d_prime\", py.d_prime, float(r_res.rx2(\"d.prime\")[0]))\n",
    "    compare(\"se_d_prime\", py.se_d_prime, float(r_res.rx2(\"se\")[0]))\n",
    "    compare(\"log_likelihood\", py.log_likelihood, float(r_res.rx2(\"logLik\")[0]))\n",
    "    compare(\"p_value\", py.p_value, float(r_res.rx2(\"p.value\")[0]))\n",
    "    \n",
    "    # Compare tau estimates\n",
    "    r_tau = list(r_res.rx2(\"tau\"))\n",
    "    for i, (py_t, r_t) in enumerate(zip(py.tau, r_tau)):\n",
    "        compare(f\"tau[{i}]\", py_t, r_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. `dod_fit()` and `optimal_tau()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senspy import optimal_tau, par2prob_dod\n",
    "\n",
    "print(\"=\" * 95)\n",
    "print(\"11. dod_fit() and optimal_tau()\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "# optimal_tau\n",
    "for dp in [0.5, 1.0, 2.0]:\n",
    "    for ncat in [3, 4, 5]:\n",
    "        py_tau = optimal_tau(dp, n_categories=ncat)\n",
    "        r_tau = sensR.optimal_tau(dp, **{\"n.cat\": ncat})\n",
    "        print(f\"\\n--- optimal_tau d'={dp}, n_cat={ncat} ---\")\n",
    "        for i in range(len(py_tau)):\n",
    "            compare(f\"tau[{i}]\", py_tau[i], float(r_tau[i]))\n",
    "\n",
    "# par2prob_dod\n",
    "print(\"\\n--- par2prob_dod ---\")\n",
    "tau = np.array([1.0, 2.0, 3.0])\n",
    "dp = 1.5\n",
    "py_prob = par2prob_dod(tau, dp)\n",
    "r_prob = sensR.par2prob_dod(FloatVector(tau), dp)\n",
    "r_prob_matrix = np.array(r_prob).reshape(2, -1)\n",
    "for i in range(py_prob.shape[0]):\n",
    "    for j in range(py_prob.shape[1]):\n",
    "        label = f\"prob[{['same','diff'][i]},{j}]\"\n",
    "        compare(label, py_prob[i, j], r_prob_matrix[i, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. `discrim_power()` / `dprime_power()` — Power Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"12. Power analysis — discrim_power() / dprime_power()\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "# discrim_power\n",
    "print(\"\\n--- discrim_power ---\")\n",
    "power_cases = [\n",
    "    {\"pd_a\": 0.5, \"n\": 100, \"p_guess\": 1/3, \"stat\": \"exact\"},\n",
    "    {\"pd_a\": 0.3, \"n\": 50, \"p_guess\": 0.5, \"stat\": \"exact\"},\n",
    "    {\"pd_a\": 0.4, \"n\": 80, \"p_guess\": 1/3, \"stat\": \"normal\"},\n",
    "]\n",
    "\n",
    "for tc in power_cases:\n",
    "    py_pow = discrim_power(pd_a=tc[\"pd_a\"], sample_size=tc[\"n\"],\n",
    "                           p_guess=tc[\"p_guess\"], statistic=tc[\"stat\"])\n",
    "    r_pow = sensR.discrimPwr(tc[\"pd_a\"], tc[\"n\"],\n",
    "                              **{\"pGuess\": tc[\"p_guess\"]}, statistic=tc[\"stat\"])\n",
    "    compare(f\"power pd_a={tc['pd_a']}, n={tc['n']}\", py_pow, float(r_pow[0]))\n",
    "\n",
    "# dprime_power\n",
    "print(\"\\n--- dprime_power ---\")\n",
    "dp_power_cases = [\n",
    "    {\"d_prime_a\": 1.0, \"n\": 100, \"method\": \"triangle\", \"stat\": \"exact\"},\n",
    "    {\"d_prime_a\": 1.5, \"n\": 50, \"method\": \"twoafc\", \"stat\": \"exact\"},\n",
    "    {\"d_prime_a\": 2.0, \"n\": 80, \"method\": \"duotrio\", \"stat\": \"exact\"},\n",
    "]\n",
    "\n",
    "for tc in dp_power_cases:\n",
    "    py_pow = dprime_power(d_prime_a=tc[\"d_prime_a\"], sample_size=tc[\"n\"],\n",
    "                          method=tc[\"method\"], statistic=tc[\"stat\"])\n",
    "    r_pow = sensR.discrimPwr(\n",
    "        float(rescale(d_prime=tc[\"d_prime_a\"], method=tc[\"method\"]).pd),\n",
    "        tc[\"n\"],\n",
    "        **{\"pGuess\": senspy.core.types.parse_protocol(tc[\"method\"]).p_guess},\n",
    "        statistic=tc[\"stat\"]\n",
    "    )\n",
    "    compare(f\"d'={tc['d_prime_a']}, {tc['method']}, n={tc['n']}\", py_pow, float(r_pow[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. `discrim_sample_size()` / `dprime_sample_size()` — Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"13. Sample size estimation\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "ss_cases = [\n",
    "    {\"pd_a\": 0.5, \"power\": 0.8, \"p_guess\": 1/3, \"stat\": \"exact\"},\n",
    "    {\"pd_a\": 0.3, \"power\": 0.9, \"p_guess\": 0.5, \"stat\": \"exact\"},\n",
    "    {\"pd_a\": 0.4, \"power\": 0.8, \"p_guess\": 1/3, \"stat\": \"normal\"},\n",
    "]\n",
    "\n",
    "for tc in ss_cases:\n",
    "    py_n = discrim_sample_size(pd_a=tc[\"pd_a\"], power=tc[\"power\"],\n",
    "                               p_guess=tc[\"p_guess\"], statistic=tc[\"stat\"])\n",
    "    r_n = sensR.discrimSS(tc[\"pd_a\"], tc[\"power\"],\n",
    "                           **{\"pGuess\": tc[\"p_guess\"]}, statistic=tc[\"stat\"])\n",
    "    compare(f\"n: pd_a={tc['pd_a']}, power={tc['power']}\", py_n, float(r_n[0]))\n",
    "\n",
    "print(\"\\n--- dprime_sample_size ---\")\n",
    "dp_ss_cases = [\n",
    "    {\"d_prime_a\": 1.0, \"power\": 0.8, \"method\": \"triangle\"},\n",
    "    {\"d_prime_a\": 1.5, \"power\": 0.9, \"method\": \"twoafc\"},\n",
    "]\n",
    "\n",
    "for tc in dp_ss_cases:\n",
    "    py_n = dprime_sample_size(d_prime_a=tc[\"d_prime_a\"], power=tc[\"power\"],\n",
    "                              method=tc[\"method\"])\n",
    "    print(f\"  sensPy n={py_n} for d'={tc['d_prime_a']}, power={tc['power']}, {tc['method']}\")\n",
    "    print(f\"  (Compare with R: sensR::findcr / manual calculation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. `dprime_test()` — Common d-prime Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"14. dprime_test() — Test common d-prime\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "correct = [80, 65, 90]\n",
    "total = [100, 100, 100]\n",
    "protocol = [\"triangle\", \"twoafc\", \"duotrio\"]\n",
    "\n",
    "for stat in [\"likelihood\", \"wald\"]:\n",
    "    for alt in [\"greater\", \"two.sided\"]:\n",
    "        print(f\"\\n--- statistic={stat}, alternative={alt} ---\")\n",
    "        \n",
    "        # Python\n",
    "        py = dprime_test(correct, total, protocol,\n",
    "                         statistic=stat, alternative=alt)\n",
    "        \n",
    "        # R\n",
    "        r_res = r(f'''\n",
    "            sensR::dprime_test(\n",
    "                correct = c({','.join(map(str, correct))}),\n",
    "                total = c({','.join(map(str, total))}),\n",
    "                protocol = c(\"{'\",\"'.join(protocol)}\"),\n",
    "                statistic = \"{stat}\",\n",
    "                alternative = \"{alt}\"\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        compare(\"d_prime\", py.d_prime, float(r_res.rx2(\"d.prime\")[0]))\n",
    "        compare(\"se_d_prime\", py.se_d_prime, float(r_res.rx2(\"se\")[0]))\n",
    "        compare(\"stat_value\", py.stat_value, float(r_res.rx2(\"stat.value\")[0]))\n",
    "        compare(\"p_value\", py.p_value, float(r_res.rx2(\"p.value\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. `dprime_compare()` — Compare d-primes Across Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"15. dprime_compare() — Test equality of d-primes\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "correct = [80, 65, 90, 45]\n",
    "total = [100, 100, 100, 100]\n",
    "protocol = [\"triangle\", \"triangle\", \"twoafc\", \"duotrio\"]\n",
    "\n",
    "for stat in [\"likelihood\", \"wald\"]:\n",
    "    print(f\"\\n--- statistic={stat} ---\")\n",
    "    \n",
    "    # Python\n",
    "    py = dprime_compare(correct, total, protocol, statistic=stat)\n",
    "    \n",
    "    # R\n",
    "    r_res = r(f'''\n",
    "        sensR::dprime_compare(\n",
    "            correct = c({','.join(map(str, correct))}),\n",
    "            total = c({','.join(map(str, total))}),\n",
    "            protocol = c(\"{'\",\"'.join(protocol)}\"),\n",
    "            statistic = \"{stat}\"\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    compare(\"d_prime (common)\", py.d_prime, float(r_res.rx2(\"d.prime\")[0]))\n",
    "    compare(\"chi_sq statistic\", py.stat_value, float(r_res.rx2(\"stat.value\")[0]))\n",
    "    compare(\"p_value\", py.p_value, float(r_res.rx2(\"p.value\")[0]))\n",
    "    compare(\"df\", py.df, float(r_res.rx2(\"df\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 16. `dprime_table()` — Per-group d-prime Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"16. dprime_table() — Individual group estimates\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "correct = [80, 65, 90]\n",
    "total = [100, 100, 100]\n",
    "protocol = [\"triangle\", \"twoafc\", \"duotrio\"]\n",
    "\n",
    "# Python\n",
    "py_table = dprime_table(correct, total, protocol)\n",
    "\n",
    "# R\n",
    "r_table = r(f'''\n",
    "    sensR::dprime_table(\n",
    "        correct = c({','.join(map(str, correct))}),\n",
    "        total = c({','.join(map(str, total))}),\n",
    "        protocol = c(\"{'\",\"'.join(protocol)}\")\n",
    "    )\n",
    "''')\n",
    "\n",
    "r_matrix = np.array(r_table)\n",
    "for i, row in enumerate(py_table):\n",
    "    print(f\"\\n--- Group {i+1}: {protocol[i]} ({correct[i]}/{total[i]}) ---\")\n",
    "    compare(f\"d_prime\", row.d_prime, r_matrix[i])\n",
    "    compare(f\"se\", row.se, r_matrix[i + len(py_table)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 17. `sdt()` / `roc()` / `auc()` — Signal Detection Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"17. sdt() / roc() / auc() — Signal Detection Theory\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "# Contingency table: 2 x J (signal/noise rows, J response categories)\n",
    "table = np.array([\n",
    "    [30, 40, 20, 10],   # signal (hits descending confidence)\n",
    "    [5, 15, 30, 50],    # noise (false alarms descending confidence)\n",
    "])\n",
    "\n",
    "# SDT\n",
    "print(\"\\n--- sdt() ---\")\n",
    "py_sdt = sdt(table)\n",
    "r_sdt = sensR.SDT(ro.r.matrix(IntVector(table.flatten()), nrow=2, byrow=True))\n",
    "r_sdt_matrix = np.array(r_sdt)\n",
    "n_criteria = py_sdt.shape[0]\n",
    "for i in range(n_criteria):\n",
    "    compare(f\"d_prime[{i}]\", py_sdt[i, 2], r_sdt_matrix[i + 2 * n_criteria])  # 3rd column\n",
    "\n",
    "# AUC\n",
    "print(\"\\n--- auc() ---\")\n",
    "for dp in [0.5, 1.0, 2.0, 3.0]:\n",
    "    py_auc = auc(dp)\n",
    "    r_auc = sensR.AUC(dp)\n",
    "    compare(f\"AUC d'={dp}\", py_auc.value, float(r_auc[0]))\n",
    "\n",
    "print(\"\\n--- auc() with SE and CI ---\")\n",
    "py_auc = auc(1.5, se_d=0.3)\n",
    "r_auc = sensR.AUC(1.5, **{\"se.d\": 0.3})\n",
    "compare(\"AUC value\", py_auc.value, float(r_auc.rx2(\"AUC\")[0]))\n",
    "compare(\"AUC lower\", py_auc.lower, float(r_auc.rx2(\"lower\")[0]))\n",
    "compare(\"AUC upper\", py_auc.upper, float(r_auc.rx2(\"upper\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 18. `pc_to_pd()` / `pd_to_pc()` — Simple Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"18. pc_to_pd() / pd_to_pc() — Direct conversions\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "p_guesses = [1/3, 0.5, 0.1]\n",
    "\n",
    "for pg in p_guesses:\n",
    "    print(f\"\\n--- p_guess = {pg:.4f} ---\")\n",
    "    for pc_val in [0.5, 0.7, 0.9, 1.0]:\n",
    "        if pc_val >= pg:\n",
    "            py_pd = float(pc_to_pd(pc_val, pg))\n",
    "            r_pd = float(sensR.pc2pd(pc_val, pg)[0])\n",
    "            compare(f\"pc2pd pc={pc_val}\", py_pd, r_pd)\n",
    "    \n",
    "    for pd_val in [0.0, 0.3, 0.5, 1.0]:\n",
    "        py_pc = float(pd_to_pc(pd_val, pg))\n",
    "        r_pc = float(sensR.pd2pc(pd_val, pg)[0])\n",
    "        compare(f\"pd2pc pd={pd_val}\", py_pc, r_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 19. Comprehensive Cross-Protocol Comparison\n",
    "\n",
    "A systematic test of `discrim()` across all protocols with a fixed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"19. Cross-protocol comparison — discrim() for all protocols\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "all_protocols = [\"triangle\", \"duotrio\", \"twoafc\", \"threeafc\", \"tetrad\"]\n",
    "# Use 70/100 as a common test case\n",
    "correct, total = 70, 100\n",
    "\n",
    "rows = []\n",
    "for method in all_protocols:\n",
    "    py = discrim(correct, total, method=method)\n",
    "    r_res = sensR.discrim(correct, total, method=method)\n",
    "    r_coef = stats.coef(r_res)\n",
    "    \n",
    "    rows.append({\n",
    "        \"protocol\": method,\n",
    "        \"py_dprime\": py.d_prime,\n",
    "        \"R_dprime\": float(r_coef.rx2(\"d.prime\")[0]),\n",
    "        \"py_pc\": py.pc,\n",
    "        \"R_pc\": float(r_coef.rx2(\"pc\")[0]),\n",
    "        \"py_pd\": py.pd,\n",
    "        \"R_pd\": float(r_coef.rx2(\"pd\")[0]),\n",
    "        \"py_pval\": py.p_value,\n",
    "        \"R_pval\": float(r_res.rx2(\"p.value\")[0]),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"dprime_diff\"] = abs(df[\"py_dprime\"] - df[\"R_dprime\"])\n",
    "df[\"pc_diff\"] = abs(df[\"py_pc\"] - df[\"R_pc\"])\n",
    "df[\"pd_diff\"] = abs(df[\"py_pd\"] - df[\"R_pd\"])\n",
    "df[\"pval_diff\"] = abs(df[\"py_pval\"] - df[\"R_pval\"])\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nMax d-prime diff: {df['dprime_diff'].max():.2e}\")\n",
    "print(f\"Max p-value diff: {df['pval_diff'].max():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 20. Summary — Final Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 95)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 95)\n",
    "print(\"\"\"\n",
    "Functions validated:\n",
    "  1.  discrim()           - discrimination analysis (all protocols & statistics)\n",
    "  2.  discrim() CI        - confidence intervals (d_prime, pc, pd)\n",
    "  3.  discrim() similarity- similarity tests with d_prime0\n",
    "  4.  rescale()           - pc/pd/d_prime conversions\n",
    "  5.  psyfun/psyinv/deriv - psychometric link functions\n",
    "  6.  betabin()           - beta-binomial overdispersion model\n",
    "  7.  twoac()             - 2-AC protocol analysis\n",
    "  8.  samediff()          - same-different protocol\n",
    "  9.  anota()             - A-Not-A protocol\n",
    "  10. dod()               - degree of difference model\n",
    "  11. dod_fit/optimal_tau - DOD utilities\n",
    "  12. discrim_power()     - power analysis\n",
    "  13. sample_size()       - sample size estimation\n",
    "  14. dprime_test()       - common d-prime hypothesis test\n",
    "  15. dprime_compare()    - d-prime equality test\n",
    "  16. dprime_table()      - per-group d-prime table\n",
    "  17. sdt/roc/auc         - signal detection theory\n",
    "  18. pc2pd/pd2pc         - direct conversions\n",
    "  19. Cross-protocol      - systematic all-protocol comparison\n",
    "\n",
    "Review any FAIL lines above to investigate discrepancies.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
